{
  
    
        "post0": {
            "title": "Spotify Top 200 Charted Songs From December 2019-2021 Popularity Study",
            "content": "Music preference changes over 2019 ~ 2021 from Top 200 Songs on Spotify Global Chart . Date: March 13, 2022 . By: Ophelia, Anh, Anthony . Introduction . Pandemic quarantines have largely altered people’s schedules and daily routines. Three years into the pandemic, people around the world have experienced multiple phases of COVID infection and different quarantine measures. We are interested to see how music preferences - measured by genre popularity - changes over different periods of COVID surge and drops, full lockdowns and flexible quarantines, summer and winter. Specifically, how does song attributes, such as tempo, valence, chord, associate with a song’s popularity? Essentially, with regard to the ongoing pandemic, our research question is how did the relationship between genre popularity and song attributes change over 2019 - 2021 for top 200 songs on Spotify Global Chart? . One might ask, “why does this matter?” Well music isn’t just music, our analysis could potentially gather information on how Spotify listeners were feeling during the pandemic. This could be useful for marketing firms that want to appeal to their audiences while promoting items and services to them. In essence through sentiment analysis via marketing, firms could get to know their customers better. If a marketing firm doesn’t know what their customer wants then they won’t know what to recommend to them. . In addition to music consumption preferences revealing customers&#39; sentiments, music is used in advertising. This could be exhibited with how jingles are utilized to keep a message stuck in people’s minds. When a marketing firm learns the sentiments of their customers they could utilize music in ads that is relevant to the musical taste of the present moment. In sum, music is not just music, it could be used as a tool that surveillance capitalists such as Google could use to increase their profits and meet customers where they are at. Those who don’t have sentiments against surveillance capitalism believe there is nothing wrong with assisting consumers find what they want. While those who are against surveillance capitalism would believe this is a violation of user privacy and is akin to running a psychological experiment on individuals without their knowledge. Due to this ethical questions arise with this dataset on how it should be used. . Methods . For this project, we are using a dataset of Spotify 200 Charts (2020-2021) retrieved from Sashank Pillai on Kaggle. The link to the dataset is found on https://www.kaggle.com/sashankpillai/spotify-top-200-charts-20202021. The dataset utilizes information from spotifycharts.com and the Spotify Python API to retrieve different aspects and attributes of top hit songs within the past two years, from pre-Covid to post-Covid. . The columns in the dataset includes: Highest Charting Position, Number of Times Charted, Week of Highest Charting,Song Name, Song ID, Streams, Artist, Artist Followers, Genre, Release Date, Weeks Charted, Popularity, Danceability, Acousticness, Energy, Instrumentalness, Liveness, Loudness, Speechiness, Tempo, Valence, and Chord. A more detailed discussion of each of the attributes can be found on the Kaggle website. . In this project, we will utilize certain attributes in the dataset and Python plotting libraries like Pandas, matplotlib, Sklearn, etc. to explore patterns and trends to conclude in regards to how each attribute contributed to a song popularity over time. . The structure of our analysis is . Data cleaning (removal of rows with missing variables) | Exploratory Data Analysis | Trends of Popular Song Attributes over Time | Multiple Linear Regression Model | . Results . Data Cleaning . import pandas as pd import numpy as np import re import seaborn as sns from datetime import datetime from matplotlib import pyplot as plt from mpl_toolkits.mplot3d import Axes3D from sklearn import preprocessing from sklearn.linear_model import LinearRegression from sklearn.metrics import mean_squared_error, r2_score . df = pd.read_csv(&quot;spotify_dataset.csv&quot;) . We will create a new dataframe with the cleaned variables to conduct analysis. This new dataframe with cleaned variables will be called cleaned_df. When we finishing cleaning all data, we will add it to this dataframe. . cleaned_df=pd.DataFrame() . To begin our analysis, we will first take a general look on the dataset. . df.head() . Index Highest Charting Position Number of Times Charted Week of Highest Charting Song Name Streams Artist Artist Followers Song ID Genre ... Danceability Energy Loudness Speechiness Acousticness Liveness Tempo Duration (ms) Valence Chord . 0 1 | 1 | 8 | 2021-07-23--2021-07-30 | Beggin&#39; | 48,633,449 | Måneskin | 3377762 | 3Wrjm47oTz2sjIgck11l5e | [&#39;indie rock italiano&#39;, &#39;italian pop&#39;] | ... | 0.714 | 0.8 | -4.808 | 0.0504 | 0.127 | 0.359 | 134.002 | 211560 | 0.589 | B | . 1 2 | 2 | 3 | 2021-07-23--2021-07-30 | STAY (with Justin Bieber) | 47,248,719 | The Kid LAROI | 2230022 | 5HCyWlXZPP0y6Gqq8TgA20 | [&#39;australian hip hop&#39;] | ... | 0.591 | 0.764 | -5.484 | 0.0483 | 0.0383 | 0.103 | 169.928 | 141806 | 0.478 | C#/Db | . 2 3 | 1 | 11 | 2021-06-25--2021-07-02 | good 4 u | 40,162,559 | Olivia Rodrigo | 6266514 | 4ZtFanR9U6ndgddUvNcjcG | [&#39;pop&#39;] | ... | 0.563 | 0.664 | -5.044 | 0.154 | 0.335 | 0.0849 | 166.928 | 178147 | 0.688 | A | . 3 4 | 3 | 5 | 2021-07-02--2021-07-09 | Bad Habits | 37,799,456 | Ed Sheeran | 83293380 | 6PQ88X9TkUIAUIZJHW2upE | [&#39;pop&#39;, &#39;uk pop&#39;] | ... | 0.808 | 0.897 | -3.712 | 0.0348 | 0.0469 | 0.364 | 126.026 | 231041 | 0.591 | B | . 4 5 | 5 | 1 | 2021-07-23--2021-07-30 | INDUSTRY BABY (feat. Jack Harlow) | 33,948,454 | Lil Nas X | 5473565 | 27NovPIUIRrOZoCHxABJwK | [&#39;lgbtq+ hip hop&#39;, &#39;pop rap&#39;] | ... | 0.736 | 0.704 | -7.409 | 0.0615 | 0.0203 | 0.0501 | 149.995 | 212000 | 0.894 | D#/Eb | . 5 rows × 23 columns . After a quick manual inspection, we realize there are some empty rows, and we will remove them in the line of code below. . df = df.drop(index=[35,163,464,530,636,654,750,784,876,1140,1538],axis=1) . Exploratory Data Analysis . We start our data cleaning process by looking at the data distribution of all the variables that we are interested in to investigate whether there are abnormal data distributions that require further cleaning. First, we look at the variable in interest, Popularity. Below is a summary statistics and a historgram of the data. . Popularity . The resulting graph shows a relatively normal distribution that is skewed right, with some outliers towards the zero-end of the number line. The skewed right distribution is appropriate for the dataset that we are using, since the dataset specifically looks at the Most Highly Rated songs on Spotify, so the high Popularity values are expected from the context of the dataset. . df[&quot;Popularity&quot;].astype(float).describe() . . count 1545.000000 mean 70.089320 std 15.824034 min 0.000000 25% 65.000000 50% 73.000000 75% 80.000000 max 100.000000 Name: Popularity, dtype: float64 . ax = df[&#39;Popularity&#39;].astype(&#39;float&#39;).plot.hist(title=&#39;Frequency of Popularity values across the dataset&#39;) ax.set(xlabel=&#39;Popularity&#39;) . . [Text(0.5, 0, &#39;Popularity&#39;)] . cleaned_df[&#39;Popularity&#39;] = df[&#39;Popularity&#39;].astype(float) . Next, we look at our &#39;Duration&#39; variable. Immediately, we realize that the variable &#39;Duration&#39; is measured in ms, milliseconds. This does not make logical sense, so we will change it into minutes. . Duration . duration_m = [] count = 160 for i in df[&quot;Duration (ms)&quot;]: duration_m.append(round(int(i)/(1000*60),2)) . cleaned_df[&#39;Duration (min)&#39;] = duration_m . The graph below also shows a normal distribution that is skewed left. In the context of songs, this also makes sense as most song&#39;s duration averages around 3-4 minutes, which is shown in our graph with the highest peak at 3-4 minutues. However, it should be noted that there are few outliers with some values above 8 minutes. We won&#39;t be removing the outliers as we want to reflect a genuine situation on the dataset, and not alter the data to fit our analysis. . ax = cleaned_df[&#39;Duration (min)&#39;].plot.hist(title=&#39;Frequency of Song duration in minutes&#39;) ax.set(xlabel=&#39;Duration (min)&#39;) . . [Text(0.5, 0, &#39;Duration (min)&#39;)] . Then, we look at the distribution of some other numerical variables in this dataset. . cleaned_df[[&#39;Danceability&#39;,&#39;Energy&#39;, &#39;Loudness&#39;, &#39;Speechiness&#39;, &#39;Acousticness&#39;, &#39;Liveness&#39;, &#39;Tempo&#39;,&#39;Valence&#39;]]=df[[&#39;Danceability&#39;,&#39;Energy&#39;, &#39;Loudness&#39;, &#39;Speechiness&#39;, &#39;Acousticness&#39;, &#39;Liveness&#39;, &#39;Tempo&#39;,&#39;Valence&#39;]].astype(float) . Histogram of numerical columns . To look at all of our other columns in greater detail, we decided to plot every column to explore the distribution of our dataset and get a general overview of the data that we are presented with. . cleaned_df[cleaned_df.columns[1:]].hist(figsize=(20, 20)) plt.show() . . The 9 graphs display the distribution of Duration (mins), Danceability, Energy, Loudness, Speechiness, Acousticness, Liveness, Tempo, and Valence. Most of the graphs show a normal distribution. From the overview, we can take notes of a few things: . Songs with high &#39;Danceability&#39; and &#39;Energy&#39; are favored (with these graphs being skewed right heavily. | Song with smaller, or softer, &#39;Loudness&#39; is preferred since the Loudness graph is skewed right towards 0. Since all of our data shows all negative values with no positive values, we can infer that songs that are softer and quieter than the standard threshold of 0 dB were more liked rather than loud. | In regards to &#39;Speechiness&#39;, we can see that the data is skewed left with &gt;80% of data points are near 0. This shows that most of the popular songs had few words and mostly melody. | This goes in line with the &#39;Acousticness&#39; graph as it is also skewed left. Since there were few words spoken in these popular tracks, we expect that Acousticness levels would be low as well. | The &#39;Liveness&#39; graph is also skewed left, signifying that most of these songs were recorded in the studio rather than being performed live. | The &#39;Tempo&#39; graph shows a normal distribution that is slightly skewed left. Most of the tempo for the popular tracks is in the 80-140bpm range. | The &#39;Valence&#39; graph also shows a pretty even normal distribution. However, when looking at it more closely, we can see that more than 50% of songs have &gt;0.4 valence, meaning people liked more positive and euphoric tracks with high valence. | Heatmap showing correlations between variables . plt.figure(figsize=(20, 10)) sns.heatmap(cleaned_df[cleaned_df.columns[1:]].corr(),annot=True) plt.show() . . We computed a heatmap between all of our independent variables to see whether there is any correlation when comparing each attribute side by side. Overall, there are not many correlations within independent variables as most values are 0.1 or below. However, we can see some higher correlation with &#39;Energy&#39; and &#39;Loudness&#39;, showing a correlational value of 0.73. In context, this information makes sense as higher energy songs tend to be louder as well. On the other hand, &#39;Energy&#39; and &#39;Loudness&#39; both have a negative correlation with &#39;Acousticness&#39;. This is also valid since these generally louder and energized songs would mean lower acoustics. Some other slight positive correlation is &#39;Danceability&#39;, &#39;Energy&#39;, &#39;Loudness&#39; that have a slight positive correlation with &#39;Valence&#39; with values 0.30 and 0.36 correlation. This makes sense as we can expect more positive and vibrant song to have higher &#39;Danceability&#39;, &#39;Energy&#39;, and &#39;Loudness&#39; in regards to how these attributes can make the listener feel more happy with these upbeat rhythm and tunes. . Creating a Time column using Week of Highest Charting column . Since we are looking to assess the trends and patterns in the songs attributes over time, we want to create a new column that will get us this &quot;Time&quot; variable. To do so, we use the &#39;Week of Highest Charting&#39; variable to extract a substring that contains the Day, Month, and Year of the beginning of the week of its charting. This information will allow us to bucket the songs data into months starting from 2019 to 2021. . df[&quot;Week of Highest Charting&quot;][0] # 5-6 indices are Month, 0-3 indices are Year . &#39;2021-07-23--2021-07-30&#39; . From the first value in the &#39;Week of Highest Charting&#39;, we can see that index 0 to 9 in the string represent the information we are looking for. We use this to slice the string and extract the information that we need to create our new &#39;Time of Highest Charting&#39; column for a more general and representative Time value that can be plotted. We convert it to a datetime object for proper sorting against the x-axis. . cleaned_df[&#39;Time of Highest Charting&#39;] = df[&quot;Week of Highest Charting&quot;].str.slice(0,10) cleaned_df[&#39;Time of Highest Charting&#39;] = pd.to_datetime(cleaned_df[&#39;Time of Highest Charting&#39;], format=&#39;%Y-%m-%d&#39;) . cleaned_df.head() . Popularity Duration (min) Danceability Energy Loudness Speechiness Acousticness Liveness Tempo Valence Time of Highest Charting . 0 100.0 | 3.53 | 0.714 | 0.800 | -4.808 | 0.0504 | 0.1270 | 0.3590 | 134.002 | 0.589 | 2021-07-23 | . 1 99.0 | 2.36 | 0.591 | 0.764 | -5.484 | 0.0483 | 0.0383 | 0.1030 | 169.928 | 0.478 | 2021-07-23 | . 2 99.0 | 2.97 | 0.563 | 0.664 | -5.044 | 0.1540 | 0.3350 | 0.0849 | 166.928 | 0.688 | 2021-06-25 | . 3 98.0 | 3.85 | 0.808 | 0.897 | -3.712 | 0.0348 | 0.0469 | 0.3640 | 126.026 | 0.591 | 2021-07-02 | . 4 96.0 | 3.53 | 0.736 | 0.704 | -7.409 | 0.0615 | 0.0203 | 0.0501 | 149.995 | 0.894 | 2021-07-23 | . Trends of Popular Song Attributes over Time . Now, we want to look at the trends of different song attributes over time that is more than comparing these independent variables with one another. To pivot, we create a new column using the &#39;Week of Highest Charting&#39; to deduce the time period that the song is most popular so that we can plot our data points on a timeline. Here, we are converting our previously independent variables of song attributes into dependent variables to plot against our new independent variable -- Time. . First, we grouped all of the data points that have the same Time of Highest Charting into buckets and find the average values of all the items in that group of each attribute. We also take the absolute values of the &#39;Loudness&#39; column for more convenient plotting when plot against other values since this is the only column with negative values. . columns = [&#39;Popularity&#39;, &#39;Duration (min)&#39;, &#39;Danceability&#39;, &#39;Energy&#39;, &#39;Loudness&#39;, &#39;Speechiness&#39;, &#39;Acousticness&#39;, &#39;Liveness&#39;, &#39;Tempo&#39;, &#39;Valence&#39;] trend_df = cleaned_df.groupby([&#39;Time of Highest Charting&#39;]).mean() trend_df[&#39;Loudness&#39;] = trend_df[&#39;Loudness&#39;].abs() trend_df . Popularity Duration (min) Danceability Energy Loudness Speechiness Acousticness Liveness Tempo Valence . Time of Highest Charting . 2019-12-27 72.707865 | 3.355281 | 0.714843 | 0.657483 | 5.509517 | 0.106035 | 0.230712 | 0.166566 | 123.478517 | 0.541694 | . 2020-01-03 75.380000 | 3.192800 | 0.713440 | 0.595360 | 6.121700 | 0.106986 | 0.234130 | 0.149078 | 114.316980 | 0.490260 | . 2020-01-10 60.409091 | 3.232273 | 0.744182 | 0.576273 | 7.015364 | 0.181300 | 0.233218 | 0.181627 | 124.783727 | 0.532218 | . 2020-01-17 64.769231 | 3.619744 | 0.748154 | 0.598385 | 7.384333 | 0.176254 | 0.219311 | 0.214546 | 121.996769 | 0.426174 | . 2020-01-24 51.000000 | 3.265556 | 0.716833 | 0.506889 | 8.530556 | 0.181672 | 0.355717 | 0.155344 | 128.838444 | 0.466556 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 2021-06-25 79.375000 | 3.557083 | 0.631750 | 0.678042 | 6.182958 | 0.188233 | 0.240930 | 0.260633 | 123.527208 | 0.519917 | . 2021-07-02 81.608696 | 3.609565 | 0.722652 | 0.757826 | 4.541522 | 0.079109 | 0.138393 | 0.155004 | 128.456261 | 0.670217 | . 2021-07-09 83.000000 | 3.132500 | 0.656917 | 0.553083 | 6.169917 | 0.100633 | 0.310403 | 0.267583 | 121.317250 | 0.552917 | . 2021-07-16 68.533333 | 3.228000 | 0.660400 | 0.647533 | 7.028800 | 0.169227 | 0.233333 | 0.179447 | 124.086667 | 0.520800 | . 2021-07-23 83.755556 | 3.151556 | 0.705733 | 0.691333 | 5.596378 | 0.095904 | 0.248058 | 0.155591 | 123.672667 | 0.600511 | . 83 rows × 10 columns . row_index = trend_df.index.values type(row_index) . numpy.ndarray . We then normalize all of these values so that they are between 0 and 1, and we were able to do so using the preprocessing library of sklearn. We set the index values of each row as the date formed previously using the function groupby(). We now have a new DataFrame with normalized average values that is grouped by the week that the songs hit top charts. This information is stored in scaled_df. . d = preprocessing.normalize(trend_df, axis=0) scaled_df = pd.DataFrame(d, columns=columns) scaled_df . Popularity Duration (min) Danceability Energy Loudness Speechiness Acousticness Liveness Tempo Valence . 0 0.111776 | 0.111274 | 0.112817 | 0.112600 | 0.095588 | 0.087643 | 0.097900 | 0.098470 | 0.109909 | 0.114407 | . 1 0.115884 | 0.105886 | 0.112595 | 0.101961 | 0.106210 | 0.088429 | 0.099350 | 0.088131 | 0.101754 | 0.103544 | . 2 0.092868 | 0.107195 | 0.117447 | 0.098692 | 0.121714 | 0.149853 | 0.098963 | 0.107374 | 0.111070 | 0.112406 | . 3 0.099571 | 0.120045 | 0.118074 | 0.102479 | 0.128116 | 0.145682 | 0.093062 | 0.126835 | 0.108590 | 0.090009 | . 4 0.078404 | 0.108298 | 0.113131 | 0.086810 | 0.148002 | 0.150161 | 0.150944 | 0.091836 | 0.114680 | 0.098538 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 78 0.122025 | 0.117967 | 0.099703 | 0.116121 | 0.107272 | 0.155584 | 0.102236 | 0.154080 | 0.109952 | 0.109808 | . 79 0.125459 | 0.119707 | 0.114049 | 0.129785 | 0.078794 | 0.065387 | 0.058726 | 0.091635 | 0.114339 | 0.141552 | . 80 0.127598 | 0.103886 | 0.103675 | 0.094721 | 0.107046 | 0.083178 | 0.131716 | 0.158189 | 0.107985 | 0.116777 | . 81 0.105358 | 0.107053 | 0.104224 | 0.110896 | 0.121947 | 0.139874 | 0.099012 | 0.106085 | 0.110450 | 0.109994 | . 82 0.128760 | 0.104518 | 0.111379 | 0.118397 | 0.097095 | 0.079270 | 0.105260 | 0.091982 | 0.110081 | 0.126829 | . 83 rows × 10 columns . scaled_df.index = list(row_index) scaled_df . Popularity Duration (min) Danceability Energy Loudness Speechiness Acousticness Liveness Tempo Valence . 2019-12-27 0.111776 | 0.111274 | 0.112817 | 0.112600 | 0.095588 | 0.087643 | 0.097900 | 0.098470 | 0.109909 | 0.114407 | . 2020-01-03 0.115884 | 0.105886 | 0.112595 | 0.101961 | 0.106210 | 0.088429 | 0.099350 | 0.088131 | 0.101754 | 0.103544 | . 2020-01-10 0.092868 | 0.107195 | 0.117447 | 0.098692 | 0.121714 | 0.149853 | 0.098963 | 0.107374 | 0.111070 | 0.112406 | . 2020-01-17 0.099571 | 0.120045 | 0.118074 | 0.102479 | 0.128116 | 0.145682 | 0.093062 | 0.126835 | 0.108590 | 0.090009 | . 2020-01-24 0.078404 | 0.108298 | 0.113131 | 0.086810 | 0.148002 | 0.150161 | 0.150944 | 0.091836 | 0.114680 | 0.098538 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 2021-06-25 0.122025 | 0.117967 | 0.099703 | 0.116121 | 0.107272 | 0.155584 | 0.102236 | 0.154080 | 0.109952 | 0.109808 | . 2021-07-02 0.125459 | 0.119707 | 0.114049 | 0.129785 | 0.078794 | 0.065387 | 0.058726 | 0.091635 | 0.114339 | 0.141552 | . 2021-07-09 0.127598 | 0.103886 | 0.103675 | 0.094721 | 0.107046 | 0.083178 | 0.131716 | 0.158189 | 0.107985 | 0.116777 | . 2021-07-16 0.105358 | 0.107053 | 0.104224 | 0.110896 | 0.121947 | 0.139874 | 0.099012 | 0.106085 | 0.110450 | 0.109994 | . 2021-07-23 0.128760 | 0.104518 | 0.111379 | 0.118397 | 0.097095 | 0.079270 | 0.105260 | 0.091982 | 0.110081 | 0.126829 | . 83 rows × 10 columns . Line graphs of Song Attributes . We want to plot these new values side-by-side with our response variable, Popularity, to explore whether we can find a pattern of each attribute linked with the songs&#39; Popularity and how these changes over time. Note that &#39;Popularity&#39; is plotted in RED to highlight that this is the baseline of the response variable that we want to compare all other numerical variables against. . Popularity/Danceability/Energy trends over Time . ax = scaled_df[[&#39;Popularity&#39;, &#39;Danceability&#39;, &#39;Energy&#39;]].plot(kind=&#39;line&#39;, title=&#39;Popularity/Danceability/Energy trends over time&#39;, figsize=(20,5), color=[&#39;red&#39;,&#39;lightgreen&#39;,&#39;cornflowerblue&#39;]) ax.set(xlabel=&#39;Time of Highest Charting&#39;) . . [Text(0.5, 0, &#39;Time of Highest Charting&#39;)] . First, we look at &#39;Popularity&#39;, &#39;Danceability&#39;, and &#39;Energy&#39; trends side-by-side. It can be noted that there is a big dip in songs popularity near the end of January 2020, the lowest peak in mid-December 2020, and mid-February 2021. . We see peaks in &#39;Danceability&#39; in early April 2020, early July 2020, and late December 2021 near the lowest peak of &#39;Popularity&#39;. For &#39;Energy&#39;, we see peaks in March 2020, mid-July 2020, and early January 2021. Overall, we see that songs with higher &#39;Danceability&#39; are generally coupled with higher &#39;Energy&#39;. There are few discrepancies where these 2 attributes are rising but &#39;Popularity&#39; hit its lowest peaks, specifically in mid-January 2020 and late December 2020. . Over time, both the Danceability and Energy of songs generally stay in the higher range. . Popularity/Speechiness/Acousticness trends over Time . ax = scaled_df[[&#39;Popularity&#39;, &#39;Speechiness&#39;, &#39;Acousticness&#39;]].plot(kind=&#39;line&#39;, title=&#39;Popularity/Speechiness/Acousticness trends over time&#39;, figsize=(20,5), color=[&#39;red&#39;,&#39;gold&#39;,&#39;lightsalmon&#39;]) ax.set(xlabel=&#39;Time of Highest Charting&#39;) . . [Text(0.5, 0, &#39;Time of Highest Charting&#39;)] . In this graph, we see that &#39;Acousticness&#39; peaked in late July 2020 and late December 2020. On the other hand, &#39;Speechiness&#39; peaked in early May 2020 and early July 2021. There are more low peaks of &#39;Speechiness&#39; over the past 3 years compared to its high peaks, showing that people preferred songs with fewer words spoken. Acousticness are generally low over time as well with only the 2 outstanding peaks mentioned above. This graph shows that popular songs were generally low in both &#39;Speechiness&#39; and &#39;Acousticness&#39; over the past few years. . Popularity/Liveness/Acousticness trends over Time . ax = scaled_df[[&#39;Popularity&#39;, &#39;Loudness&#39;, &#39;Liveness&#39;]].plot(kind=&#39;line&#39;, title=&#39;Popularity/Liveness/Acousticness trends over time&#39;, figsize=(20,5), color=[&#39;red&#39;,&#39;paleturquoise&#39;,&#39;mediumpurple&#39;]) ax.set(xlabel=&#39;Time of Highest Charting&#39;) . . [Text(0.5, 0, &#39;Time of Highest Charting&#39;)] . For &#39;Liveness&#39;, this graph has 3 highest peaks in June 2020, late December 2021, and March 2021. However, we can see that at every of these peaks, there was a dip in both &#39;Loudness&#39; and &#39;Popularity&#39; when looking at it in the bigger picture. For &#39;Loudness&#39;, songs generally stay in the average to above average range and rarely falls below the average across the past 3 years. . Popularity/Tempo/Valence trends over Time . ax = scaled_df[[&#39;Popularity&#39;, &#39;Tempo&#39;, &#39;Valence&#39;]].plot(kind=&#39;line&#39;, title=&#39;Popularity/Tempo/Valence trends over time&#39;, figsize=(20,5), color=[&#39;red&#39;,&#39;tan&#39;,&#39;lightskyblue&#39;]) ax.set(xlabel=&#39;Time of Highest Charting&#39;) . . [Text(0.5, 0, &#39;Time of Highest Charting&#39;)] . In regards to &#39;Tempo,&#39; we see that most songs tempo stays within an average range over the years with no noticeable peaks or dips. On the other hand, &#39;Valence&#39; has greater range on how the value changes with the highest peak in January 2021. Since the range of &#39;Valence&#39; is wider, we can infer that songs with both lower and higher Valence were both favorited, with a slight preference for songs that are happier. . Multiple Linear Regression Analysis . As previously stated, we are interested in how people&#39;s music tastes have evolved from before covid and covid times. We are using a song&#39;s popularity to represent people&#39;s music taste. . Thus, statistically, we are interested to see what factor contribute to what degree of change in a song&#39;s popularity. We want to answer question like, on average, . how much more popular are songs produced in 2020-2021, comparing to those produced in 2019? | for every unit change in a song&#39;s loudness level, how does popularity changes? | . In this section, we will explain how we tried to explore this topic from a Multiple Linear Regression. Popularity in this dataset is measured on a continuous scale from 1-100. Thus, we are thinking of using the Linear Regression model rather than logistic, random forest and other classication ones from skylearn. . To measure popularity, we will use the Popularity column as our response variable. . We are interested in song attributes, and we want to avoid variables as artist followers and streams, as they could be highly correlated and thus resulting in multi-collinearity conditions, which are not desirable in a linear regression. . Below are our independent variables: . Numerical values . Danceability | Energy | Loudness | Speechiness | Acousticness | Liveness | Tempo | Duration (ms) | Valence | . Dummy ones . Week of Highest Charting | Genre | . A total of 11 independent variables. . Previously in the Exploratory Data Analysis, we already introduced the cleaned_df. We will inherited this dataframe and use it to do modeling work. First, we will change categorical variables into dummy variables. . Dummy variables creation - Genre, Time . Variable Genre becomes dummy_genre . 1: pop | 0: not-pop | . ith_row = 0 cleaned_genre_col = [] for i in df[&quot;Genre&quot;]: x=re.split(&quot;&#39;&quot;,i) # avoids songs with no genre attribute if len(x) &gt; 1: cleaned_genre_col.append(x[1]) else: cleaned_genre_col.append(&#39; &#39;) . dummy_genre = [] for i in cleaned_genre_col: if re.search(&#39;pop&#39;,i): dummy_genre.append(1) else: dummy_genre.append(0) . Variable Week of Highest Charting becomes dummy_time . To create a dummy variable of time, we are using Week of Highest Charting, separating songs charted in 2019 and those charted in 2020, 2021. . 2020 ~ 2021, covid: 1 | 2019, pre-coivd: 0 | . dummy_time = [] for i in df[&quot;Week of Highest Charting&quot;]: if re.match(&#39;2019&#39;,i): dummy_time.append(0) else : dummy_time.append(1) . cleaned_df[&#39;Time&#39;] = dummy_time cleaned_df[&#39;Genre&#39;] = dummy_genre . cleaned_df = cleaned_df.drop(&#39;Time of Highest Charting&#39;,axis=1) . Below is a preview of our cleaned data for statistical linear regression analysis . cleaned_df.head() . Popularity Duration (min) Danceability Energy Loudness Speechiness Acousticness Liveness Tempo Valence Time Genre . 0 100.0 | 3.53 | 0.714 | 0.800 | -4.808 | 0.0504 | 0.1270 | 0.3590 | 134.002 | 0.589 | 1 | 0 | . 1 99.0 | 2.36 | 0.591 | 0.764 | -5.484 | 0.0483 | 0.0383 | 0.1030 | 169.928 | 0.478 | 1 | 0 | . 2 99.0 | 2.97 | 0.563 | 0.664 | -5.044 | 0.1540 | 0.3350 | 0.0849 | 166.928 | 0.688 | 1 | 1 | . 3 98.0 | 3.85 | 0.808 | 0.897 | -3.712 | 0.0348 | 0.0469 | 0.3640 | 126.026 | 0.591 | 1 | 1 | . 4 96.0 | 3.53 | 0.736 | 0.704 | -7.409 | 0.0615 | 0.0203 | 0.0501 | 149.995 | 0.894 | 1 | 0 | . Construction of our MLR model. . X=np.array(cleaned_df[cleaned_df.columns[1:]]) Y=np.array(cleaned_df[&#39;Popularity&#39;]) # The linear regression reg = LinearRegression().fit(X, Y) # Predicted Y values Y_predicted = reg.intercept_ + cleaned_df[&#39;Duration (min)&#39;]*reg.coef_[0] + cleaned_df[&#39;Danceability&#39;]*reg.coef_[1] + cleaned_df[&#39;Energy&#39;]*reg.coef_[2] + cleaned_df[&#39;Loudness&#39;]*reg.coef_[3] + cleaned_df[&#39;Speechiness&#39;]*reg.coef_[4] + cleaned_df[&#39;Acousticness&#39;]*reg.coef_[5] + cleaned_df[&#39;Liveness&#39;]*reg.coef_[6]+cleaned_df[&#39;Tempo&#39;]*reg.coef_[7]+ cleaned_df[&#39;Valence&#39;]*reg.coef_[8]+cleaned_df[&#39;Time&#39;]*reg.coef_[9] + cleaned_df[&#39;Genre&#39;]*reg.coef_[10] . Model Coefficients . From the coefficients below, we could see that on average, songs produced in 2020-2021 are 1.4 units less popular for those produced in 2019. (Note: for the variable Time, 2019 songs are coded as &#39;0&#39;, thus calculated part of the linear intercept. Thus, we know this coefficient reflects the change for songs in 2020-2021 from those in 2019). | We also notice that songs for a pop song, its popularity increases 4.87 from a non-pop song (looking at variable &#39;Genre&#39;). | Other variables&#39; infuence on popularity levels are rather small, ranging from 1~2 points mostly. | . coef=pd.DataFrame(list(reg.coef_),columns=[&#39;Coefficients&#39;]) coef[&#39;Variables&#39;]=cleaned_df.columns[1:] coef . Coefficients Variables . 0 1.229682 | Duration (min) | . 1 1.923650 | Danceability | . 2 -1.850428 | Energy | . 3 1.051961 | Loudness | . 4 1.903326 | Speechiness | . 5 -1.706396 | Acousticness | . 6 -2.715815 | Liveness | . 7 -0.015298 | Tempo | . 8 -2.938005 | Valence | . 9 -1.415745 | Time | . 10 4.876493 | Genre | . Model Accuracy . To check the model reliability, we will use the mean square error (mse) and r^2. As shown below, the mse is incredibly large and the r^2 scores are very small. This indicates that the our predicted models fitted the actual data poorly. It means that our predictions of how changes in the a song&#39; attributes (independant variables) will affect the song&#39;s popularity is inaccurate. . mean_squared_error(Y,Y_predicted) . 236.31240409002564 . r2_score(Y, Y_predicted) . 0.055649316950793226 . Construction of 3D graphs of a reduced MLR model to explore possible reasons for model failure . It would be nice if we could learn the reasons for why our model failed. Visualizations would be the most direct method. Yet, multiple Linear Regression (MLR) plots are difficle to show as they are not in the 2D space, but n dimensional ones. . Thus, to get a simple visualization to explore possible causes for model failure, we will use a reduced number of predictors, two in this case, to show a 3D graph and get an idea of the multiple-dimensions that we are dealing with right now. . First, we extract the first two columns as X1, that is Duration (min) and Danceability. We fit a linear regression using X1 and Y. The 3D scatterplot shows how our linear regression with X1 variables worked. . The variable on x-axis is Duration (min). | The variable on y-axis is Danceability. | The variable on the z-axi is Popularity. | The red dots represent actual datapoints in the dataset. | The blue plane represents our predicted values. | . The plot is shown from two different angles. . X1 = np.array(cleaned_df[cleaned_df.columns[1:3]]) reg = LinearRegression().fit(X1, Y) . fig = plt.figure(figsize=(20,10)) # first plot the points ax=fig.add_subplot(111,projection=&#39;3d&#39;) ax.scatter(X1[:,0], X1[:,1],Y, marker=&#39;.&#39;,color=&#39;red&#39;) ax.set_xlabel(&#39;Duration (min)&#39;) ax.set_ylabel(&#39;Danceability&#39;) ax.set_zlabel(&#39;Popularity&#39;) # add the blue plane with predicted values xs=np.tile(np.arange(0.0,8.0,0.4),(20,1)) ys=np.tile(np.arange(0.0,1.0,0.05),(20,1)).T zs=xs*reg.coef_[0]+ys*reg.coef_[1]+reg.intercept_ ax.plot_surface(xs,ys,zs,alpha=0.5) ax.view_init(10, 100) plt.show() . . fig = plt.figure(figsize=(20,10)) ax=fig.add_subplot(111,projection=&#39;3d&#39;) ax.scatter(X1[:,0], X1[:,1],Y, marker=&#39;.&#39;,color=&#39;red&#39;) ax.set_xlabel(&#39;Duration (min)&#39;) ax.set_ylabel(&#39;Danceability&#39;) ax.set_zlabel(&#39;Popularity&#39;) xs=np.tile(np.arange(0.0,8.0,0.4),(20,1)) ys=np.tile(np.arange(0.0,1.0,0.05),(20,1)).T zs=xs*reg.coef_[0]+ys*reg.coef_[1]+reg.intercept_ ax.plot_surface(xs,ys,zs,alpha=0.5) ax.view_init(10, 0) plt.show() . . Comment on the 3D graph . A clustering effect appears: there is a small number of songs with low popularities, and a lot of songs with mid-high range of popularities. But these two different clusters are not caused by the two independent variables, as we see the only difference between these two groups are their popularity measures, their x and y ranges are similar with the songs of higher popularities. | For Duration (min), data is clustered around 2~6 minutes. This makes sense as that is the usual range for a song that we listen to. | The Danceability is centered around 0.4 ~ 1.0, as we look at the graph from a different angle. | This clustering effect in these two variables makes sense. Going back to earlier visualizations of histograms on individual dependent and independant variables, we see most variables have values centered around a peak. | We also realize that our predicted linear plane is very weak. It barely has a slope. With the clusters and our poor plane shape, we could safely claim that Duration (min) and Danceability are two weak predictors for song Popularity. | . Possible cause of model failure . Similarly, for the reasons the reduced model failed to predict song popularity, our big model with all 11 independant models might failed due to a clustering effect within the data. Our model does not capture that. . Discussion . What does our analysis show? . When using simple data visualization plotting tools, our analysis of how the numerical values of technical song attributes in our dataset change over time did not show a clear positive or negative trend when plotting these values against Time. However, looking at these graphs, we can see how some independent variables follow the same upward or downward trends when plotting together (i.e. songs with high Danceability generally comes with high Energy). It is also interesting to see that when comparing how these values changed against Popularity, Popularity actually hit its lowest peaks while some attributes might be hitting its highest peak in the same time period. Nonetheless, since these trends are not consistent across the entire dataset, it is difficult to draw a conclusive conclusion in regards to the trends of these variables over time since we do not have enough convincing data points. . Our analysis using a Multiple Linear Regression model shows that song attributes, such as acousticness, tempo, valence, are general bad predictors for songs&#39; popularity. It is hard to see how Spotify users&#39; tastes changed from 2019 ~ 2021 using this model. . Something noticeable is that, based on our model, songs&#39; popularity level actually decreases from pre-covid to covid times. Perhaps, there are some uniformality amongst songs produced pre-covid. Yet, our model failed to include the variables that could explain this. We also see that music Genre could play a big role in a song&#39;s popularity, that an average pop songs&#39; popular level is 4 points more than that of non-pop song. However, the &#39;Genre&#39; variable is our analysis is simplified. We reduced it to simply pop, non-pop. Perhaps, using logistic regressions, classification methods with more nuanced genre level, we would be able to better discover the relationship between a song&#39;s genre and its popularity. . Limitations . In our line graphs plotted against time, a potential limitation is that we could not plot every single data points in the same graphs and were required to simplify them by grouping songs that are popular in the same weeks and getting the averages of our data points. If we were able to display these data points in more detail, then we could have been able to draw more conclusive results using our line graphs . A big limitation of our modeling analysis is our choice of model and predictors. We chose a linear method because we wanted to use Popularity as a continuous measure, but now after the analysis, it does not seem like a great idea. From the 3D graph with reduced variables, we could see that there is a clustering effect on the data, rather linear. The relationship between the independent and dependent variables is probably not linear. Using a classifying method such as KNN or Random Forest may be a better idea. . Another limitation would be our predictor choice. Looking at the 3D graph, one discovers that a song&#39;s popular level could not be explained with the chosen predictors. The 11 predictors we&#39;ve chosen are mostly associated with songs&#39; technical attributes. Maybe a song&#39;s popularity is less related to its technicality, but to the specific artist, to the lyrics. Perhaps to measure a song&#39;s popularity, we should use another response variable, such as how many times that the song has been in the Top 200 Chart, for how many days it stayed there. . The third limitation would be on the dataset. It starts at the end of 2019, thus we have an uneven amount of data for songs charted in 2019 versus those in 2020 and 2021. . Conclusion, big pictures, words of advice . From our analysis on how a song&#39;s technical attributes (i.e., tempo, valence, etc) relates to its popularity, using multiple linear regression, and a spotify dataset on the top 200 songs from 2019 - 2021, we were not able to produce much fruitful analysis. We cannot give a definite answer on what variables attributed to songs&#39; popularities, and how that has been changed since covid. We can say that there are some difference in songs&#39; popularities produced in 2019 and those produced after, and that pop songs are more popular than non-pop songs. But we cannot speak on other technical aspects of the songs. . Our model has low accuracies, measured using mse and r^2. We suspect this failure is due to 1) incorrect model choice - there does not exist a linear relationship between the variables we chose, 2) incorrect parameter choice - perhaps there is no relationship between songs&#39; technical attributes and their popularity. . For those who are interested in this analysis, we suggest using 1) classification methods like logistic regressions and KNN, 2) parameters related to the artists and not song attributes (e.g., artist followers), new measure of popularity (i.e., do not use Spotify&#39;s pre-existing Popularity measure, use alternative ones like highest charted position), and more nuanced categorical variables, such as dividng &#39;Genre&#39; into categories more detailed than &#39;pop&#39; and &#39;non-pop&#39;, and divide the &#39;time&#39; period by seasons, holidays, etc. . collapse-hide . Each member&#39;s contribution to this project . Ophelia: data cleaning and EDA visualizations; MLR modeling, visualizations and comments; discussion and conclusion; powerpoint; binder | Anh: comments and analysis in EDA; popularities vs. song attributes plots and comments; discussion; powerpoint | Anthony: project introductions and methods; powerpoint | .",
            "url": "https://opheliadh.github.io/Spotify_MusicTrends/fastpages/jupyter/2022/03/14/Spotify_songs_popularity.html",
            "relUrl": "/fastpages/jupyter/2022/03/14/Spotify_songs_popularity.html",
            "date": " • Mar 14, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://opheliadh.github.io/Spotify_MusicTrends/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://opheliadh.github.io/Spotify_MusicTrends/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://opheliadh.github.io/Spotify_MusicTrends/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://opheliadh.github.io/Spotify_MusicTrends/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}